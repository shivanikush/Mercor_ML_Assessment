{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0120b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fashion_input import *\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "from simple_resnet import *\n",
    "from hyper_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6908eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'logs_' + FLAGS.version + '/'\n",
    "TRAIN_LOG_PATH = FLAGS.version + '_error.csv'\n",
    "\n",
    "REPORT_FREQ = 50\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALI_BATCH_SIZE = 25\n",
    "TEST_BATCH_SIZE = 25\n",
    "FULL_VALIDATION = False\n",
    "Error_EMA = 0.98\n",
    "\n",
    "STEP_TO_TRAIN = 45000\n",
    "DECAY_STEP0 = 25000\n",
    "DECAY_STEP1 = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580e3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_batch(df):\n",
    "    offset = np.random.choice(len(df) - VALI_BATCH_SIZE, 1)[0]\n",
    "    validation_df = df.iloc[offset:offset+VALI_BATCH_SIZE, :]\n",
    "\n",
    "    validation_batch, validation_label, validation_bbox_label = load_data_numpy(validation_df)\n",
    "    return validation_batch, validation_label, validation_bbox_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49fc6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    '''\n",
    "    The class defining the training process and relevant helper functions\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.placeholders()\n",
    "\n",
    "    def loss(self, logits, bbox, labels, bbox_labels):\n",
    "        labels = tf.cast(labels, tf.int64)\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='cross_entropy_per_example')\n",
    "        mse_loss = tf.reduce_mean(tf.losses.mean_squared_error(bbox_labels, bbox), name='mean_square_loss')\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "        return cross_entropy_mean + mse_loss\n",
    "\n",
    "    def top_k_error(self, predictions, labels, k):\n",
    "        batch_size = predictions.get_shape().as_list()[0]\n",
    "        in_top1 = tf.to_float(tf.nn.in_top_k(predictions, labels, k=1))\n",
    "        num_correct = tf.reduce_sum(in_top1)\n",
    "        return (batch_size - num_correct) / float(batch_size)\n",
    "\n",
    "\n",
    "    def placeholders(self):\n",
    "        self.image_placeholder = tf.placeholder(dtype=tf.float32, shape=[TRAIN_BATCH_SIZE,\n",
    "                                                                        IMG_ROWS, IMG_COLS, 3])\n",
    "        self.label_placeholder = tf.placeholder(dtype=tf.int32, shape=[TRAIN_BATCH_SIZE])\n",
    "        self.bbox_placeholder = tf.placeholder(dtype=tf.float32, shape=[TRAIN_BATCH_SIZE, 4])\n",
    "\n",
    "        self.vali_image_placeholder = tf.placeholder(dtype=tf.float32, shape=[VALI_BATCH_SIZE,\n",
    "                                                                IMG_ROWS, IMG_COLS, 3])\n",
    "        self.vali_label_placeholder = tf.placeholder(dtype=tf.int32, shape=[VALI_BATCH_SIZE])\n",
    "        self.vali_bbox_placeholder = tf.placeholder(dtype=tf.float32, shape=[VALI_BATCH_SIZE, 4])\n",
    "\n",
    "        self.lr_placeholder = tf.placeholder(dtype=tf.float32, shape=[])\n",
    "        self.dropout_prob_placeholder = tf.placeholder(dtype=tf.float32, shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af9077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_operation(self, global_step, total_loss, top1_error):\n",
    "        tf.summary.scalar('learning_rate', self.lr_placeholder)\n",
    "        tf.summary.scalar('train_loss', total_loss)\n",
    "        tf.summary.scalar('train_top1_error', top1_error)\n",
    "\n",
    "        ema = tf.train.ExponentialMovingAverage(0.95, global_step)\n",
    "        train_ema_op = ema.apply([total_loss, top1_error])\n",
    "        tf.summary.scalar('train_top1_error_avg', ema.average(top1_error))\n",
    "        tf.summary.scalar('train_loss_avg', ema.average(total_loss))\n",
    "\n",
    "        opt = tf.train.MomentumOptimizer(learning_rate=self.lr_placeholder, momentum=0.9)\n",
    "        train_op = opt.minimize(total_loss, global_step=global_step)\n",
    "        return train_op, train_ema_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6eeae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def validation_op(self, validation_step, top1_error, loss):\n",
    "        ema = tf.train.ExponentialMovingAverage(0.0, validation_step)\n",
    "        ema2 = tf.train.ExponentialMovingAverage(0.95, validation_step)\n",
    "        val_op = tf.group(validation_step.assign_add(1), ema.apply([top1_error, loss]), ema2.apply([top1_error, loss]))\n",
    "        top1_error_val = ema.average(top1_error)\n",
    "        top1_error_avg = ema2.average(top1_error)\n",
    "        loss_val = ema.average(loss)\n",
    "        loss_val_avg = ema2.average(loss)\n",
    "        tf.summary.scalar('val_top1_error', top1_error_val)\n",
    "        tf.summary.scalar('val_top1_error_avg', top1_error_avg)\n",
    "        tf.summary.scalar('val_loss', loss_val)\n",
    "        tf.summary.scalar('val_loss_avg', loss_val_avg)\n",
    "        return val_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf002f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def full_validation(self, validation_df, sess, vali_loss, vali_top1_error, batch_data, batch_label, batch_bbox):\n",
    "        num_batches = len(validation_df) // VALI_BATCH_SIZE\n",
    "        error_list = []\n",
    "        loss_list = []\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            offset = i * VALI_BATCH_SIZE\n",
    "            vali_batch_df = validation_df.iloc[offset:offset+VALI_BATCH_SIZE, :]\n",
    "            validation_image_batch, validation_labels_batch, validation_bbox_batch = load_data_numpy(vali_batch_df)\n",
    "\n",
    "            vali_error, vali_loss_value = sess.run([vali_top1_error, vali_loss],\n",
    "                                              {self.image_placeholder: batch_data,\n",
    "                                                     self.label_placeholder: batch_label,\n",
    "                                                    self.bbox_placeholder:batch_bbox,\n",
    "                                                     self.vali_image_placeholder: validation_image_batch,\n",
    "                                                     self.vali_label_placeholder: validation_labels_batch,\n",
    "                                                    self.vali_bbox_placeholder: validation_bbox_batch,\n",
    "                                                     self.lr_placeholder: FLAGS.learning_rate,\n",
    "                                                     self.dropout_prob_placeholder: 0.5})\n",
    "            error_list.append(vali_error)\n",
    "            loss_list.append(vali_loss_value)\n",
    "\n",
    "        return np.mean(error_list), np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "413d45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def train(self):\n",
    "        train_df = prepare_df(FLAGS.train_path, usecols=['image_path', 'category', 'x1_modified', 'y1_modified', 'x2_modified', 'y2_modified'])\n",
    "        vali_df = prepare_df(FLAGS.vali_path, usecols=['image_path', 'category', 'x1_modified', 'y1_modified', 'x2_modified', 'y2_modified'])\n",
    "\n",
    "        num_train = len(train_df)\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        validation_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "\n",
    "        logits, bbox, _ = inference(self.image_placeholder, n=FLAGS.num_residual_blocks, reuse=False,\n",
    "                                    keep_prob_placeholder=self.dropout_prob_placeholder)\n",
    "        vali_logits, vali_bbox, _ = inference(self.vali_image_placeholder, n=FLAGS.num_residual_blocks,\n",
    "                                         reuse=True, keep_prob_placeholder=self.dropout_prob_placeholder)\n",
    "\n",
    "\n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        loss = self.loss(logits, bbox, self.label_placeholder, self.bbox_placeholder)\n",
    "        full_loss = tf.add_n([loss] + reg_losses)\n",
    "\n",
    "        predictions = tf.nn.softmax(logits)\n",
    "        top1_error = self.top_k_error(predictions, self.label_placeholder, 1)\n",
    "        vali_loss = self.loss(vali_logits, vali_bbox, self.vali_label_placeholder, self.vali_bbox_placeholder)\n",
    "        vali_predictions = tf.nn.softmax(vali_logits)\n",
    "        vali_top1_error = self.top_k_error(vali_predictions, self.vali_label_placeholder, 1)\n",
    "\n",
    "\n",
    "        train_op, train_ema_op = self.train_operation(global_step, full_loss, top1_error)\n",
    "        val_op = self.validation_op(validation_step, vali_top1_error, vali_loss)\n",
    "\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess = tf.Session()\n",
    "\n",
    "        if FLAGS.continue_train_ckpt is True:\n",
    "            print('Model restored!')\n",
    "            saver.restore(sess, FLAGS.ckpt_path)\n",
    "        else:\n",
    "            sess.run(init)\n",
    "        summary_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "\n",
    "        step_list = []\n",
    "        train_error_list = []\n",
    "        vali_error_list = []\n",
    "        min_error = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6860df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(STEP_TO_TRAIN):\n",
    "    offset = np.random.choice(num_train - TRAIN_BATCH_SIZE, 1)[0]\n",
    "\n",
    "            train_batch_df = train_df.iloc[offset:offset+TRAIN_BATCH_SIZE, :]\n",
    "            batch_data, batch_label, batch_bbox = load_data_numpy(train_batch_df)\n",
    "\n",
    "            vali_image_batch, vali_labels_batch, vali_bbox_batch = generate_validation_batch(vali_df)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            if step == 0:\n",
    "                if FULL_VALIDATION is True:\n",
    "                    top1_error_value, vali_loss_value = self.full_validation(vali_df,\n",
    "                                                                             sess=sess,\n",
    "                                                            vali_loss=vali_loss,\n",
    "                                                            vali_top1_error=vali_top1_error,\n",
    "                                                            batch_data=batch_data,\n",
    "                                                            batch_label=batch_label,\n",
    "                                                            batch_bbox=batch_bbox)\n",
    "                    vali_summ = tf.Summary()\n",
    "                    vali_summ.value.add(tag='full_validation_error',\n",
    "                                    simple_value=top1_error_value.astype(np.float))\n",
    "                    vali_summ.value.add(tag='full_validation_loss',\n",
    "                                    simple_value=vali_loss_value.astype(np.float))\n",
    "                    summary_writer.add_summary(vali_summ, step)\n",
    "                    summary_writer.flush()\n",
    "\n",
    "                else:\n",
    "                    _, top1_error_value, vali_loss_value = sess.run([val_op, vali_top1_error,\n",
    "                                                                     vali_loss],\n",
    "                                                    {self.image_placeholder: batch_data,\n",
    "                                                     self.label_placeholder: batch_label,\n",
    "                                                     self.vali_image_placeholder: vali_image_batch,\n",
    "                                                     self.vali_label_placeholder: vali_labels_batch,\n",
    "                                                     self.lr_placeholder: FLAGS.learning_rate,\n",
    "                                                     self.bbox_placeholder: batch_bbox,\n",
    "                                                     self.vali_bbox_placeholder: vali_bbox_batch,\n",
    "                                                     self.dropout_prob_placeholder: 1.0})\n",
    "                print('Validation top1 error = %.4f' % top1_error_value)\n",
    "                print('Validation loss = ', vali_loss_value)\n",
    "                print('----------------------------')\n",
    "\n",
    "\n",
    "            _, _, loss_value, train_top1_error = sess.run([train_op, train_ema_op, loss,\n",
    "                    top1_error], {self.image_placeholder: batch_data,\n",
    "                                  self.label_placeholder: batch_label,\n",
    "                                  self.bbox_placeholder: batch_bbox,\n",
    "                                  self.vali_image_placeholder: vali_image_batch,\n",
    "                                  self.vali_label_placeholder: vali_labels_batch,\n",
    "                                  self.vali_bbox_placeholder: vali_bbox_batch,\n",
    "                                  self.lr_placeholder: FLAGS.learning_rate,\n",
    "                                  self.dropout_prob_placeholder: 0.5})\n",
    "            duration = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd99472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if step % REPORT_FREQ == 0:\n",
    "               summary_str = sess.run(summary_op, {self.image_placeholder: batch_data,\n",
    "                                                   self.label_placeholder: batch_label,\n",
    "                                                   self.bbox_placeholder: batch_bbox,\n",
    "                                                   self.vali_image_placeholder: vali_image_batch,\n",
    "                                                   self.vali_label_placeholder: vali_labels_batch,\n",
    "                                                   self.vali_bbox_placeholder: vali_bbox_batch,\n",
    "                                                   self.lr_placeholder: FLAGS.learning_rate,\n",
    "                                                    self.dropout_prob_placeholder: 0.5})\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "\n",
    "                num_examples_per_step = TRAIN_BATCH_SIZE\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = float(duration)\n",
    "\n",
    "                format_str = ('%s: step %d, loss = %.4f (%.1f examples/sec; %.3f ' 'sec/batch)')\n",
    "                print (format_str % (datetime.now(), step, loss_value, examples_per_sec, sec_per_batch))\n",
    "                print('Train top1 error = ', train_top1_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "029fcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "                if FULL_VALIDATION is True:\n",
    "                    top1_error_value, vali_loss_value = self.full_validation(vali_df,\n",
    "                                                                             sess=sess,\n",
    "                                                            vali_loss=vali_loss,\n",
    "                                                            vali_top1_error=vali_top1_error,\n",
    "                                                            batch_data=batch_data,\n",
    "                                                            batch_label=batch_label,\n",
    "                                                            batch_bbox=batch_bbox)\n",
    "                    vali_summ = tf.Summary()\n",
    "                    vali_summ.value.add(tag='full_validation_error',\n",
    "                                    simple_value=top1_error_value.astype(np.float))\n",
    "                    vali_summ.value.add(tag='full_validation_loss',\n",
    "                                    simple_value=vali_loss_value.astype(np.float))\n",
    "                    summary_writer.add_summary(vali_summ, step)\n",
    "                    summary_writer.flush()\n",
    "\n",
    "                else:\n",
    "\n",
    "                    _, top1_error_value, vali_loss_value = sess.run([val_op, vali_top1_error,\n",
    "                                                                 vali_loss],\n",
    "                                                {self.image_placeholder: batch_data,\n",
    "                                                 self.label_placeholder: batch_label,\n",
    "                                                 self.bbox_placeholder: batch_bbox,\n",
    "                                                 self.vali_image_placeholder: vali_image_batch,\n",
    "                                                 self.vali_label_placeholder: vali_labels_batch,\n",
    "                                                 self.vali_bbox_placeholder: vali_bbox_batch,\n",
    "                                                 self.lr_placeholder: FLAGS.learning_rate,\n",
    "                                                 self.dropout_prob_placeholder: 0.5})\n",
    "\n",
    "#                 print('Validation top1 error = %.4f' % top1_error_value)\n",
    "#                 print('Validation loss = ', vali_loss_value)\n",
    "#                 print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2140fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if top1_error_value < min_error:\n",
    "                    min_error = top1_error_value\n",
    "                    checkpoint_path = os.path.join(TRAIN_DIR, 'min_model.ckpt')\n",
    "                    saver.save(sess, checkpoint_path, global_step=step)\n",
    "                    print('Current lowest error = ', min_error)\n",
    "\n",
    "                step_list.append(step)\n",
    "                train_error_list.append(train_top1_error)\n",
    "                vali_error_list.append(top1_error_value)\n",
    "\n",
    "\n",
    "            if step == DECAY_STEP0 or step == DECAY_STEP1:\n",
    "                FLAGS.learning_rate = FLAGS.learning_rate * 0.1\n",
    "\n",
    "\n",
    "            if step % 10000 == 0 or (step + 1) == STEP_TO_TRAIN:\n",
    "                checkpoint_path = os.path.join(TRAIN_DIR, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "                error_df = pd.DataFrame(data={'step':step_list, 'train_error':\n",
    "                    train_error_list, 'validation_error': vali_error_list})\n",
    "                error_df.to_csv(TRAIN_DIR + TRAIN_LOG_PATH, index=False)\n",
    "\n",
    "            if (step + 1) == STEP_TO_TRAIN:\n",
    "                checkpoint_path = os.path.join(TRAIN_DIR, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "                error_df = pd.DataFrame(data={'step': step_list, 'train_error':\n",
    "                    train_error_list, 'validation_error': vali_error_list})\n",
    "                error_df.to_csv(TRAIN_DIR + TRAIN_LOG_PATH, index=False)\n",
    "\n",
    "   #    print('Training finished!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "910b3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self):\n",
    "        self.test_image_placeholder = tf.placeholder(dtype=tf.float32, shape=[25, IMG_ROWS,\n",
    "                                                                              IMG_COLS, 3])\n",
    "        self.test_label_placeholder = tf.placeholder(dtype=tf.int32, shape=[25])\n",
    "\n",
    "        # Build test graph\n",
    "        logits, global_pool = inference(self.test_image_placeholder, n=FLAGS.num_residual_blocks, reuse=False,\n",
    "                                              keep_prob_placeholder=self.dropout_prob_placeholder)\n",
    "        predictions = tf.nn.softmax(logits)\n",
    "        test_error = self.top_k_error(predictions, self.test_label_placeholder, 1)\n",
    "\n",
    "        saver = tf.train.Saver(tf.all_variables())\n",
    "        sess = tf.Session()\n",
    "        saver.restore(sess, FLAGS.test_ckpt_path)\n",
    "     #   print('Model restored!')\n",
    "    #    ##########################\n",
    "\n",
    "        test_df = prepare_df(FLAGS.test_path, usecols=['image_path', 'category', 'x1', 'y1', 'x2', 'y2'], shuffle=False)\n",
    "        test_df = test_df.iloc[-25:, :]\n",
    "\n",
    "        prediction_np = np.array([]).reshape(-1, 6)\n",
    "        fc_np = np.array([]).reshape(-1, 64)\n",
    "        for step in range(len(test_df) // TEST_BATCH_SIZE):\n",
    "            if step % 100 == 0:\n",
    "                print('Testing %i batches...' %step)\n",
    "                if step != 0:\n",
    "                    print('Test_error = ', test_error_value)\n",
    "\n",
    "            df_batch = test_df.iloc[step*25 : (step+1)*25, :]\n",
    "            test_batch, test_label = load_data_numpy(df_batch)\n",
    "\n",
    "            prediction_batch_value, test_error_value = sess.run([predictions, test_error],\n",
    "                                                               feed_dict={\n",
    "                self.test_image_placeholder:test_batch, self.test_label_placeholder: test_label})\n",
    "            fc_batch_value = sess.run(global_pool, feed_dict={\n",
    "                self.test_image_placeholder:test_batch, self.test_label_placeholder: test_label})\n",
    "\n",
    "            prediction_np = np.concatenate((prediction_np, prediction_batch_value), axis=0)\n",
    "            fc_np = np.concatenate((fc_np, fc_batch_value))\n",
    "\n",
    "    #    print('Predictin array has shape ', fc_np.shape)\n",
    "        np.save(FLAGS.fc_path, fc_np[-5:,:])\n",
    "\n",
    "train = Train()\n",
    "train.train()\n",
    "train.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d1708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
